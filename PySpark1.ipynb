{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyN81fZKmeFcKgeEuOkHHJta"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"id":"TSjJkHUmfU6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOwoTxNiefWX"},"outputs":[],"source":["from pyspark import SparkConf,SparkContext\n","conf=SparkConf().setAppName('abc').setMaster('local') #\n","sc=SparkContext(conf=conf)\n","sc.setLogLevel('ERROR')\n","from pyspark.sql import SparkSession\n","spark=SparkSession.builder.appName('abc').config('','').getOrCreate()\n","# NUMPY Dense Vector\n","import numpy as np\n","v1=np.array([1,2,3,4,5])\n","print(v1)\n","# simple python list\n","v2=[1,2,3,4,5,6]\n","print(v2)\n","# Sparce & dense spark vector\n","from pyspark.mllib.linalg import Vectors\n","v3=Vectors.dense([3,4,5,6])\n","print(v3)\n","v4 = Vectors.sparse(3, [0, 2], [1.0, 3.0])\n","print(v4)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","df = spark.read.csv(\"/content/drive/MyDrive/ColabInputs/data.csv\",header=True,inferSchema=True) # header = None\n","df.show(5,0) # 0 doesnot truncate displaying columns, useful in large dataset"],"metadata":{"id":"xcl_grwQi41A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 3: Exploratory Data Analysis"],"metadata":{"id":"DcgM-pR0fSU4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.count()"],"metadata":{"id":"t5hp1i5skvGO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.select('Grades').distinct().count()"],"metadata":{"id":"75fPQB0Vk_6L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.printSchema()"],"metadata":{"id":"vkezG4DQlCS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.show()"],"metadata":{"id":"hvWjJqCnlQnI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe().show()"],"metadata":{"id":"zgo9dc2UlaYB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create a feature array by omitting the last column\n","feature_cols = df.columns[:-1]\n","from pyspark.ml.feature import VectorAssembler\n","vect_assembler = VectorAssembler(inputCols = feature_cols, outputCol=\"features\")\n","#Utilize Assembler created above in order to add the feature column\n","data_w_features = vect_assembler.transform(df)"],"metadata":{"id":"UlO_rCfZl_Sn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["finalized_data = data_w_features.select(\"features\",\"Grades\")\n","finalized_data.show()"],"metadata":{"id":"YXVlJarela-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train test split\n","train_dataset, test_dataset = finalized_data.randomSplit([0.7, 0.3])\n","print(df.count())\n","print(train_dataset.count())\n","print(test_dataset.count())"],"metadata":{"id":"Pk0pc-vHllw0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Import Linear Regression class called LinearRegression\n","from pyspark.ml.regression import LinearRegression\n","LinReg = LinearRegression(featuresCol=\"features\", labelCol=\"Grades\")"],"metadata":{"id":"K3Reqg3flo9F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model training and testing\n","#Train the model on the training using fit() method.\n","model = LinReg.fit(train_dataset)\n","#Predict the Grades using the evulate method\n","pred = model.evaluate(test_dataset)"],"metadata":{"id":"8oK8FtGFlu_D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred.predictions.show()"],"metadata":{"id":"_ogZwizZlxiC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Find out coefficient value\n","coefficient = model.coefficients\n","print (\"The coefficient of the model is : %a\" %coefficient)\n","#Find out intercept Value\n","intercept = model.intercept\n","print (\"The Intercept of the model is : %f\" %intercept)"],"metadata":{"id":"2p7X3rLflzh9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Evaluate the model using metric like Mean Absolute Error(MAE), Root Mean Square Error(RMSE) and R-Square\n","from pyspark.ml.evaluation import RegressionEvaluator\n","evaluation = RegressionEvaluator(labelCol=\"Grades\", predictionCol=\"prediction\")\n","# Root Mean Square Error\n","rmse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"rmse\"})\n","print(\"RMSE: %.3f\" % rmse)\n","# Mean Square Error\n","mse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mse\"})\n","print(\"MSE: %.3f\" % mse)\n","# Mean Absolute Error\n","mae = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mae\"})\n","print(\"MAE: %.3f\" % mae)\n","# r2 - coefficient of determination\n","r2 = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"r2\"})\n","print(\"r2: %.3f\" %r2)"],"metadata":{"id":"RKzpzJQLmIFO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7W4i_qzXoSpX"},"execution_count":null,"outputs":[]}]}